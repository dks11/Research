{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJmDsjcIkCkO"
      },
      "outputs": [],
      "source": [
        "!pip install --pre -U  torch transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s9IxrcvjXwg"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import gc\n",
        "import os\n",
        "import csv\n",
        "import torch.nn as nn\n",
        "import evaluate\n",
        "from datetime import datetime\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from datasets import load_metric, Dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification,get_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85PTl7fFjjlu"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "CHECKPOINT = \"xlm-roberta-base\"  # transformer model checkpoint\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CUBLAS_WORKSPACE_CONFIG = :4096:8\n",
        "os.getenv('CUBLAS_WORKSPACE_CONFIG')"
      ],
      "metadata": {
        "id": "uPKOv_9p05Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(0)\n",
        "np.random.seed(1)\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.use_deterministic_algorithms(True)\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)"
      ],
      "metadata": {
        "id": "6ltttIbSdn4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ],
      "metadata": {
        "id": "erjPBz3ocsit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "        return tokenizer(examples[\"message\"], truncation=True)"
      ],
      "metadata": {
        "id": "zKtZsSqJNnPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdOfDTmUjs_m"
      },
      "outputs": [],
      "source": [
        "def load_train_data(fileName):\n",
        "    if fileName == 0:\n",
        "      frames = []\n",
        "      for i in range(1,6):\n",
        "        df = pd.read_csv(f\"/content/enron{i}.csv\", escapechar=\"\\\\\")\n",
        "        frames.append(df)\n",
        "\n",
        "      df = pd.concat(frames)\n",
        "      #df.to_csv(\"/content/enron0.csv\", index=False, escapechar=\"\\\\\", quoting=csv.QUOTE_ALL) NOT WORKING\n",
        "\n",
        "    else:\n",
        "      df = pd.read_csv(f\"/content/enron{fileName}.csv\", escapechar=\"\\\\\")\n",
        "\n",
        "      if len(df[df['spam/ham'] == 1]) < 1500:      \n",
        "        spamframes = df[df['spam/ham'] == 1].sample(n=1500, replace=True, random_state = 42)\n",
        "      else:\n",
        "        spamframes = df[df['spam/ham'] == 1].sample(n=1500, random_state = 42)\n",
        "\n",
        "      hamframes = df[df['spam/ham'] == 0].sample(n=1500, random_state = 42)\n",
        "\n",
        "      frames = [spamframes,hamframes]\n",
        "      df = pd.concat(frames)\n",
        "\n",
        "    ham = len(df[df['spam/ham'] == 0])\n",
        "    spam = len(df[df['spam/ham'] == 1])\n",
        "\n",
        "    total = ham + spam\n",
        "    print(f\"Total = {total}\")\n",
        "    hamratio = ham / total\n",
        "    spamratio = spam / total\n",
        "\n",
        "    print(f\"Ham:{ham}\")\n",
        "    print(f\"Spam:{spam}\")\n",
        "    print(f\"Ham Ration:{hamratio}\")\n",
        "    print(f\"Spam Ration:{spamratio}\")\n",
        "\n",
        "    raw_datasets = Dataset.from_pandas(df)\n",
        "\n",
        "    raw_datasets = raw_datasets.shuffle(seed=42)\n",
        "\n",
        "    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns(\"message\")\n",
        "    tokenized_datasets = tokenized_datasets.rename_column(\"spam/ham\", \"labels\")\n",
        "    tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "    if tokenized_datasets.column_names.count(\"__index_level_0__\") > 0:\n",
        "      tokenized_datasets = tokenized_datasets.remove_columns(\"__index_level_0__\") \n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "    trainloader = DataLoader(\n",
        "        tokenized_datasets,\n",
        "        batch_size=16,\n",
        "        collate_fn=data_collator,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=g,\n",
        "    )\n",
        "    \n",
        "    return trainloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_data(fileName):\n",
        "    if fileName == 0:\n",
        "      df = pd.read_csv(f\"/content/urdu.csv\")\n",
        "\n",
        "    else:\n",
        "      df = pd.read_csv(f\"/content/urdu{fileName}.csv\", escapechar=\"\\\\\")\n",
        "\n",
        "    spamframes = df[df['spam/ham'] == 1].sample(n=100, random_state = 42)\n",
        "    hamframes = df[df['spam/ham'] == 0].sample(n=100, random_state = 42)\n",
        "\n",
        "    frames = [spamframes,hamframes]\n",
        "    df = pd.concat(frames)\n",
        "    ham = len(df[df['spam/ham'] == 0])\n",
        "    spam = len(df[df['spam/ham'] == 1])\n",
        "\n",
        "    total = ham + spam\n",
        "    print(f\"Total = {total}\")\n",
        "    hamratio = ham / total\n",
        "    spamratio = spam / total\n",
        "\n",
        "    print(f\"Ham:{ham}\")\n",
        "    print(f\"Spam:{spam}\")\n",
        "    print(f\"Ham Ration:{hamratio}\")\n",
        "    print(f\"Spam Ration:{spamratio}\")\n",
        "\n",
        "    raw_datasets = Dataset.from_pandas(df)\n",
        "    raw_datasets = raw_datasets.shuffle(seed=42)\n",
        "\n",
        "    tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "    tokenized_datasets = tokenized_datasets.remove_columns(\"message\")\n",
        "    tokenized_datasets = tokenized_datasets.rename_column(\"spam/ham\", \"labels\")\n",
        "    tokenized_datasets.set_format(\"torch\")\n",
        "    \n",
        "    if tokenized_datasets.column_names.count(\"__index_level_0__\") > 0:\n",
        "      tokenized_datasets = tokenized_datasets.remove_columns(\"__index_level_0__\") \n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "    testloader = DataLoader(\n",
        "        tokenized_datasets, batch_size=8, collate_fn=data_collator, worker_init_fn=seed_worker, generator=g\n",
        "    )\n",
        "    return testloader"
      ],
      "metadata": {
        "id": "jjfz9nFzHLqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xe48d7vFjtH1"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, epochs):\n",
        "    torch.manual_seed(1)\n",
        "    torch.cuda.manual_seed(1)\n",
        "    total_steps = len(trainloader) * epochs\n",
        "    total_train_loss = 0\n",
        "    optimizer = AdamW(net.parameters(),lr = 5e-5)\n",
        "\n",
        "    lr_scheduler = get_scheduler(\n",
        "        \"linear\", \n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=0, \n",
        "        num_training_steps=total_steps\n",
        ")\n",
        "    \n",
        "    progress_bar = tqdm(range(total_steps))\n",
        "\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "      for batch in trainloader:\n",
        "          start_time = datetime.now()\n",
        "          batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "          \n",
        "           \n",
        "          outputs = net(**batch)\n",
        "          loss = outputs.loss\n",
        "          total_train_loss += loss.item()\n",
        "          \n",
        "          loss.backward()\n",
        "          \n",
        "          optimizer.step()\n",
        "          lr_scheduler.step()\n",
        "          optimizer.zero_grad()\n",
        "          progress_bar.update(1)\n",
        "\n",
        "          \n",
        "          \n",
        "          \n",
        "          end_time = datetime.now()\n",
        "          print(\"Epoch: \"+ str(epoch + 1) + \"\\tTime: \" + str(end_time - start_time) + \"\\tLoss: \" + str((loss.item())))\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(trainloader) \n",
        "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(net, testloader):\n",
        "    accuracy_metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "    precision_metric0 = evaluate.load(\"precision\")\n",
        "    precision_metric1 = evaluate.load(\"precision\")\n",
        "\n",
        "    recall_metric0 = evaluate.load(\"recall\")\n",
        "    recall_metric1 = evaluate.load(\"recall\")\n",
        "\n",
        "    f1_metric0 = evaluate.load(\"f1\")\n",
        "    f1_metric1 = evaluate.load(\"f1\")\n",
        "\n",
        "    net.eval()\n",
        "    for batch in testloader:\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = net(**batch)\n",
        "\n",
        "        loss = outputs.loss.item()\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "        accuracy_metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "        precision_metric0.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "        recall_metric0.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "        f1_metric0.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "        precision_metric1.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "        recall_metric1.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "        f1_metric1.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "    \n",
        "    accuracy = accuracy_metric.compute()\n",
        "\n",
        "    precison0 = precision_metric0.compute(pos_label = 0)\n",
        "    precison1 = precision_metric1.compute(pos_label = 1)\n",
        "\n",
        "    recall0 = recall_metric0.compute(pos_label = 0)\n",
        "    recall1 = recall_metric1.compute(pos_label = 1)\n",
        "\n",
        "    f1_0 = f1_metric0.compute(pos_label = 0)\n",
        "    f1_1 = f1_metric1.compute(pos_label = 1)\n",
        "\n",
        "\n",
        "    return accuracy, precison0, precison1, recall0, recall1, f1_0, f1_1"
      ],
      "metadata": {
        "id": "9HCl5Eo-z_RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = load_train_data(0)\n",
        "testloader = load_test_data(1)\n"
      ],
      "metadata": {
        "id": "9YodYKsW3t7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = AutoModelForSequenceClassification.from_pretrained(\n",
        "        CHECKPOINT, num_labels=2\n",
        "    ).to(DEVICE)\n",
        "train(net, trainloader,2)"
      ],
      "metadata": {
        "id": "6o2DOwkv4bPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, precision0, precision1, recall0, recall1, f1_0, f1_1 = test(net, testloader)\n",
        "print(f\"\"\"Final test set performance:\n",
        "    \\n\\t{accuracy}\\n\\t\n",
        "\n",
        "    \\n\\t(Pos Label 0){precision0}\n",
        "    \\n\\t(Pos Label 1){precision1}\\n\\t\n",
        "\n",
        "    \\n\\t(Pos Label 0){recall0}\n",
        "    \\n\\t(Pos Label 1){recall1}\\n\\t\n",
        "\n",
        "    \\n\\t(Pos Label 0){f1_0}\n",
        "    \\n\\t(Pos Label 1){f1_1}\\n\\t\n",
        "    \"\"\")"
      ],
      "metadata": {
        "id": "OIBQu5WH3uIA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOC7CxzCsUNtBwShKwporr/"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}